{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "723d83ab",
   "metadata": {},
   "source": [
    "# Heart Disease Classification with Logistic Regression\n",
    "\n",
    "This notebook mirrors the production pipeline in `src/` and adds intuitive diagnostics so you can explain, verify, and extend the classifier before deploying it through the FastAPI service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dacf2ac",
   "metadata": {},
   "source": [
    "## 1. Experiment roadmap\n",
    "\n",
    "1. Load the heart disease dataset and review basic descriptive statistics.\n",
    "2. Visualise relationships that typically influence cardiovascular risk.\n",
    "3. Train the same scikit-learn pipeline defined in `src/pipeline.py`.\n",
    "4. Evaluate discrimination (ROC-AUC) and calibration metrics to validate probabilistic quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a60fbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    RocCurveDisplay,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    log_loss,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "DATA_PATH = Path('..') / 'data' / 'heart.csv'\n",
    "DATA_PATH.resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f2f192",
   "metadata": {},
   "source": [
    "The feature engineering and scaling steps here must stay in sync with `src/pipeline.py`. If you change preprocessing for experimentation, port those adjustments back into the production code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595a6e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b629d0",
   "metadata": {},
   "source": [
    "The dataset combines continuous measurements (blood pressure, cholesterol, heart rate) with categorical-like integers (chest pain type, thalassemia). A quick overview ensures ranges are sensible and highlights potential scaling needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66915a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sns.scatterplot(data=df, x='age', y='thalach', hue='target', ax=axes[0], palette='Set1')\n",
    "axes[0].set_title('Age vs. Max Heart Rate by Outcome')\n",
    "sns.boxplot(data=df, x='target', y='oldpeak', ax=axes[1])\n",
    "axes[1].set_title('ST Depression by Outcome')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf63eef",
   "metadata": {},
   "source": [
    "## 2. Train/validation split\n",
    "\n",
    "We recreate the stratified split from `src/data.py`. Stratification keeps the positive class proportion stable across train and validation folds so performance estimates remain reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00cfd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    'age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
    "    'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal'\n",
    "]\n",
    "TARGET = 'target'\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df[TARGET]\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73b5a47",
   "metadata": {},
   "source": [
    "## 3. Pipeline training and metrics\n",
    "\n",
    "The pipeline mirrors `HeartDiseasePipeline.build()`: standardise numeric features and fit a class-weighted logistic regression to counter mild class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf12f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', numeric_transformer, FEATURES)], remainder='drop'\n",
    ")\n",
    "clf = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(max_iter=1000, solver='liblinear', class_weight='balanced', random_state=42)),\n",
    "    ]\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "y_proba = clf.predict_proba(X_val)[:, 1]\n",
    "metrics = {\n",
    "    'accuracy': float(accuracy_score(y_val, y_pred)),\n",
    "    'precision': float(precision_score(y_val, y_pred)),\n",
    "    'recall': float(recall_score(y_val, y_pred)),\n",
    "    'f1': float(f1_score(y_val, y_pred)),\n",
    "    'roc_auc': float(roc_auc_score(y_val, y_proba)),\n",
    "    'log_loss': float(log_loss(y_val, y_proba)),\n",
    "}\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c61935",
   "metadata": {},
   "source": [
    "### Classification report\n",
    "\n",
    "A granular report helps bridge the gap between overall metrics and class-specific behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258954ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_val, y_pred))\n",
    "ConfusionMatrixDisplay.from_predictions(y_val, y_pred, display_labels=['No disease', 'Disease'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_val, y_proba)\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7cbf4b",
   "metadata": {},
   "source": [
    "## 4. Sync with production artifacts\n",
    "\n",
    "- The metrics dictionary above should match the values stored in `artifacts/metrics.json` after running `python \"Supervised Learning/Logistic Regression/src/train.py\"`.\n",
    "- If you change preprocessing or model parameters here, port them into `src/pipeline.py` to keep the FastAPI endpoint consistent.\n",
    "- Calibration concerns? Consider Platt scaling or isotonic regression and update the service to expose recalibrated probabilities."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
