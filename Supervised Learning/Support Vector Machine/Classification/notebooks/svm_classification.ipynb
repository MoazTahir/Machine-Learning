{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f89c3bf4",
   "metadata": {},
   "source": [
    "# Support Vector Machine â€” Breast Cancer Notebook\n",
    "\n",
    "This notebook mirrors the production code under `src/` and provides an exploratory playground for validating the breast cancer SVM classifier. Follow the sections in order to sanity-check the dataset, reproduce the scripted training pipeline, and capture experiments you may want to promote back into the FastAPI service.\n",
    "\n",
    "**Roadmap**\n",
    "\n",
    "- Inspect the cached dataset and confirm feature ordering.\n",
    "- Recreate the stratified train/validation split used by the CLI.\n",
    "- Train the SVM pipeline, persist artefacts, and validate key metrics.\n",
    "- Visualise the confusion matrix, ROC curve, and support vector counts.\n",
    "- Log extension ideas (kernel sweeps, calibration, monitoring hooks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aea3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Environment imports aligned with the production pipeline.\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    ConfusionMatrixDisplay,\n",
    "    RocCurveDisplay,\n",
    "    PrecisionRecallDisplay,\n",
    " )\n",
    "\n",
    "from src.config import CONFIG as SVM_CONFIG, SVMConfig\n",
    "from src.data import load_dataset, build_features, train_validation_split\n",
    "from src.pipeline import BreastCancerSVMPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e506547",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "config: SVMConfig = SVM_CONFIG\n",
    "raw_df = load_dataset(config)\n",
    "display(raw_df.head())\n",
    "print(f\"Total rows: {len(raw_df):,}\")\n",
    "print(\"Missing values per column:\")\n",
    "display(raw_df.isna().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45127a1",
   "metadata": {},
   "source": [
    "## 1. Dataset Overview\n",
    "\n",
    "Columns are normalised to snake_case so they line up with `SVMConfig.feature_columns`. The `diagnosis` target stores string labels (malignant/benign); the training helpers convert malignant to the positive class (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eea591",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = build_features(raw_df, config)\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(\"Class distribution:\")\n",
    "display(y.value_counts().rename(index={0: 'benign', 1: 'malignant'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19524e7",
   "metadata": {},
   "source": [
    "### Feature correlations\n",
    "\n",
    "High correlations between radius, perimeter, and area motivate the margin-maximising behaviour of SVMs. Explore pairplots or heatmaps before introducing dimensionality reduction or feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359566eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = X.corr().abs()\n",
    "top_corr = corr.unstack().sort_values(ascending=False)\n",
    "print(\"Top 5 absolute correlations (excluding self-pairs):\")\n",
    "display(top_corr[top_corr < 0.9999].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943bf60b",
   "metadata": {},
   "source": [
    "## 2. Train/Validation Split\n",
    "\n",
    "Replicate the deterministic 80/20 stratified split used by `src/train.py` so notebook metrics match the scripted pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9869556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_validation_split(config)\n",
    "print(f\"Train size: {X_train.shape[0]:,} | Validation size: {X_val.shape[0]:,}\")\n",
    "print(\"Training class balance:\")\n",
    "display(y_train.value_counts(normalize=True).rename(index={0: 'benign', 1: 'malignant'}))\n",
    "print(\"Validation class balance:\")\n",
    "display(y_val.value_counts(normalize=True).rename(index={0: 'benign', 1: 'malignant'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dd1474",
   "metadata": {},
   "source": [
    "## 3. Train the Production Pipeline\n",
    "\n",
    "Instantiate `BreastCancerSVMPipeline`, fit on the training fold, and persist artefacts. Rerun this cell after tweaking hyperparameters or preprocessing steps to regenerate model weights and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723e0802",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = BreastCancerSVMPipeline(config)\n",
    "metrics = pipeline.train()\n",
    "artifact_path = pipeline.save()\n",
    "metrics_path = pipeline.write_metrics(metrics)\n",
    "print(\"Training metrics:\")\n",
    "display(metrics)\n",
    "print(f\"Model artifact: {artifact_path}\")\n",
    "print(f\"Metrics file: {metrics_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc3b14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = pipeline.pipeline.predict(X_val)\n",
    "y_val_proba = pipeline.pipeline.predict_proba(X_val)[:, 1]\n",
    "metric_frame = {\n",
    "    'accuracy': float(accuracy_score(y_val, y_val_pred)),\n",
    "    'precision': float(precision_score(y_val, y_val_pred)),\n",
    "    'recall': float(recall_score(y_val, y_val_pred)),\n",
    "    'f1': float(f1_score(y_val, y_val_pred)),\n",
    "    'roc_auc': float(roc_auc_score(y_val, y_val_proba)),\n",
    "}\n",
    "display(metric_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae6195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_val,\n",
    "    y_val_pred,\n",
    "    display_labels=['benign', 'malignant'],\n",
    "    cmap='Purples',\n",
    "    colorbar=False,\n",
    "    ax=axes[0],\n",
    ")\n",
    "axes[0].set_title('Confusion matrix')\n",
    "RocCurveDisplay.from_predictions(\n",
    "    y_val,\n",
    "    y_val_proba,\n",
    "    name='SVM (RBF)',\n",
    "    ax=axes[1],\n",
    ")\n",
    "axes[1].plot([0, 1], [0, 1], linestyle='--', color='grey', alpha=0.6)\n",
    "axes[1].set_title('ROC curve')\n",
    "PrecisionRecallDisplay.from_predictions(\n",
    "    y_val,\n",
    "    y_val_proba,\n",
    "    name='SVM (RBF)',\n",
    "    ax=axes[2],\n",
    ")\n",
    "axes[2].set_title('Precision-Recall curve')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675e624a",
   "metadata": {},
   "source": [
    "## 4. Support Vector Diagnostics\n",
    "\n",
    "Surface the number of support vectors per class to reason about margin tightness and potential outliers. Inspecting the distance to the hyperplane can inform monitoring thresholds in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8027f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline.pipeline.named_steps['classifier']\n",
    "print(f\"Support vectors: {classifier.support_vectors_.shape[0]} total\")\n",
    "print(f\"Support vectors per class: {dict(zip(['benign', 'malignant'], classifier.n_support_))}\")\n",
    "margin_distances = classifier.decision_function(X_val)\n",
    "print('Margin distance summary (validation set):')\n",
    "display(pd.Series(margin_distances).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b41f597",
   "metadata": {},
   "source": [
    "## 5. Experiment Log\n",
    "\n",
    "- **Kernel sweep**: benchmark linear vs. RBF vs. polynomial kernels; capture `C`/`gamma` choices and resulting metrics.\n",
    "- **Probability calibration**: compare Platt scaling to isotonic regression with `CalibratedClassifierCV`.\n",
    "- **Feature selection**: integrate `SelectKBest` or RFE and monitor how the support vector count changes.\n",
    "- **Monitoring hooks**: track margin distances over time to detect drift or increased uncertainty in production.\n",
    "- **Batch inference**: adapt `BreastCancerService` for offline scoring pipelines (Spark, Airflow, etc.) using the same artefacts."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
